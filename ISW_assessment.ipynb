{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNUBWjyu2H0",
        "outputId": "e04c6f7a-2f66-4cb6-ebf6-3db0d925ecd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 37 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 35.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=81bc7f315aef6f3eb4e447401813788bb3c15aad20f7ec069e83129f933e5c3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing relevant libs/packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, DateType"
      ],
      "metadata": {
        "id": "xNZm7t4Au9OD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate a spark session\n",
        "spark = SparkSession.builder \\\n",
        ".appName('ISW_assessment') \\\n",
        ".master('local[*]') \\\n",
        ".config('spark.driver.memory','32G') \\\n",
        ".config('spark.ui.showConsoleProgress', True) \\\n",
        ".config('spark.sql.repl.eagerEval.enabled', True) \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "1Zp-0omM0IZB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the raw .dat file into a spark DataFrames\n",
        "df = spark.read.csv(\"dec17pub.dat\")"
      ],
      "metadata": {
        "id": "PUAYEgrFyiiB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quick preview of the raw DataFrames\n",
        "df.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wd5kjPky0_q",
        "outputId": "673a3e4a-5db7-4d52-f91f-b9a45d7ca7f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "|00000479511071912...|\n",
            "|00000479511071912...|\n",
            "|00007169100494112...|\n",
            "|00007169100494112...|\n",
            "+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the raw DataFrames into columns, according to the data dictionary, into a new DataFrames \n",
        "census = df.select(F.concat_ws(\"\",F.substring(\"_c0\", 1,15),F.substring(\"_c0\", 71,5)).alias(\"Household_id\"),\\\n",
        "                        F.concat_ws(\"/\",F.substring(\"_c0\", 18,4),F.date_format(F.to_date(F.substring(\"_c0\", 16,2), \"MM\"),\"MMM\")).alias(\"Time_of_interview\"),\\\n",
        "                        F.substring(\"_c0\", 24,3).alias(\"Final_outcome\"),\\\n",
        "                        F.substring(\"_c0\", 31,2).alias(\"Type_of_HH_unit\"),\\\n",
        "                        F.substring(\"_c0\", 33,2).alias(\"Telephone_in_house\"),\\\n",
        "                        F.substring(\"_c0\", 35,2).alias(\"Access_to_Tel\"),\\\n",
        "                        F.substring(\"_c0\", 37,2).alias(\"Phone_interview_acc\"),\\\n",
        "                        F.substring(\"_c0\", 39,2).alias(\"Family_income_range\"),\\\n",
        "                        F.substring(\"_c0\", 61,2).alias(\"Household_type\"),\\\n",
        "                        F.substring(\"_c0\", 65,2).alias(\"Type_of_interview\"),\\\n",
        "                        F.substring(\"_c0\", 91,1).alias(\"Geo_division\"),\\\n",
        "                        F.substring(\"_c0\", 139,2).alias(\"Race\"))"
      ],
      "metadata": {
        "id": "pSS1OpdIy7Kd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning up these columns\n",
        "census = census.withColumn(\"Access_to_Tel\", F.expr(\"CASE WHEN Access_to_Tel  LIKE '%1%' THEN 'YES' \" +\n",
        "           \"WHEN Access_to_Tel LIKE '%2%' THEN 'NO' END\")) \\\n",
        "           .withColumn(\"Telephone_in_house\", F.expr(\"CASE WHEN Telephone_in_house LIKE '%1%' THEN 'YES' \" +\n",
        "           \"WHEN Telephone_in_house LIKE '%2%' THEN 'NO' END\")) \\\n",
        "           .withColumn(\"Phone_interview_acc\", F.expr(\"CASE WHEN Phone_interview_acc LIKE '%1%' THEN 'YES' \" +\n",
        "           \"WHEN Phone_interview_acc LIKE '%2%' THEN 'NO' END\"))"
      ],
      "metadata": {
        "id": "ORPGZDG4EOmM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the top 10 rows\n",
        "census.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafta8fCzAQ-",
        "outputId": "1e0f8c4a-883d-47ea-cacc-566b995c9c2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+-------------+---------------+------------------+-------------+-------------------+-------------------+--------------+-----------------+------------+----+\n",
            "|        Household_id|Time_of_interview|Final_outcome|Type_of_HH_unit|Telephone_in_house|Access_to_Tel|Phone_interview_acc|Family_income_range|Household_type|Type_of_interview|Geo_division|Race|\n",
            "+--------------------+-----------------+-------------+---------------+------------------+-------------+-------------------+-------------------+--------------+-----------------+------------+----+\n",
            "|00000479511071906011|         2017/Dec|          201|              1|               YES|          YES|                YES|                  9|             1|                2|           6|   1|\n",
            "|00000479511071906011|         2017/Dec|          201|              1|               YES|          YES|                YES|                  9|             1|                2|           6|   1|\n",
            "|00007169100494106111|         2017/Dec|          201|              1|               YES|          YES|                YES|                 11|             1|                1|           6|   1|\n",
            "|00007169100494106111|         2017/Dec|          201|              1|               YES|          YES|                YES|                 11|             1|                1|           6|   1|\n",
            "|00007169100494106111|         2017/Dec|          201|              1|               YES|          YES|                YES|                 11|             1|                1|           6|   1|\n",
            "|00011017798798608011|         2017/Dec|          201|              1|               YES|          YES|                YES|                 14|             1|                1|           6|   2|\n",
            "|00011017798798608011|         2017/Dec|          201|              1|               YES|          YES|                YES|                 14|             1|                1|           6|   2|\n",
            "|00011020659338108011|         2017/Dec|          213|              1|               YES|          YES|               null|                 -1|             0|                1|           6|  -1|\n",
            "|00011028481568008111|         2017/Dec|          201|              1|               YES|          YES|                YES|                  9|             7|                1|           6|   1|\n",
            "|00011032785646906111|         2017/Dec|          201|              1|               YES|          YES|                YES|                  5|             7|                1|           6|   2|\n",
            "+--------------------+-----------------+-------------+---------------+------------------+-------------+-------------------+-------------------+--------------+-----------------+------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the DataFrames schema\n",
        "census.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_1FCVNnVczK",
        "outputId": "e0118698-378b-4b6d-97d4-d846adfa52aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Household_id: string (nullable = false)\n",
            " |-- Time_of_interview: string (nullable = false)\n",
            " |-- Final_outcome: string (nullable = true)\n",
            " |-- Type_of_HH_unit: string (nullable = true)\n",
            " |-- Telephone_in_house: string (nullable = true)\n",
            " |-- Access_to_Tel: string (nullable = true)\n",
            " |-- Phone_interview_acc: string (nullable = true)\n",
            " |-- Family_income_range: string (nullable = true)\n",
            " |-- Household_type: string (nullable = true)\n",
            " |-- Type_of_interview: string (nullable = true)\n",
            " |-- Geo_division: string (nullable = true)\n",
            " |-- Race: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a spark DataFrames to interprete the family income column\n",
        "family_income = [(1,\"LESS THAN $5,000\"),\n",
        "(2,\"5,000 TO 7,499\"),\n",
        "(3,\"7,500 TO 9,999\"),\n",
        "(4,\"10,000 TO 12,499\"),\n",
        "(5,\"12,500 TO 14,999\"),\n",
        "(6,\"15,000 TO 19,999\"),\n",
        "(7,\"20,000 TO 24,999\"),\n",
        "(8,\"25,000 TO 29,999\"),\n",
        "(9,\"30,000 TO 34,999\"),\n",
        "(10,\"35,000 TO 39,999\"),\n",
        "(11,\"40,000 TO 49,999\"),\n",
        "(12,\"50,000 TO 59,999\"),\n",
        "(13,\"60,000 TO 74,999\"),\n",
        "(14,\"75,000 TO 99,999\"),\n",
        "(15,\"100,000 TO 149,999\"),\n",
        "(16,\"150,000 OR MORE\")]\n",
        "columns = [\"code\", \"income_range\"]\n",
        "family_income_df = spark.createDataFrame(family_income, columns)"
      ],
      "metadata": {
        "id": "Su0KHbydzDXy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a spark DataFrames to interprete the Geographical division column\n",
        "geo_division = [(1,\"NEW ENGLAND\"),\n",
        "(2,\"MIDDLE ATLANTIC\"),\n",
        "(3,\"EAST NORTH CENTRAL\"),\n",
        "(4,\"WEST NORTH CENTRAL\"),\n",
        "(5,\"SOUTH ATLANTIC\"),\n",
        "(6,\"EAST SOUTH CENTRAL\"),\n",
        "(7,\"WEST SOUTH CENTRAL\"),\n",
        "(8,\"MOUNTAIN\"),\n",
        "(9,\"PACIFIC\")]\n",
        "columns = [\"code\", \"geo_div\"]\n",
        "geo_division_df = spark.createDataFrame(geo_division, columns)"
      ],
      "metadata": {
        "id": "G0c30BIlzKfE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a spark DataFrames to interprete the race column\n",
        "race = [(1,\"White Only\"),\n",
        "(2,\"Black Only\"),\n",
        "(3,\"American Indian, Alaskan Native Only\"),\n",
        "(4,\"Asian Only\"),\n",
        "(5,\"Hawaiian/Pacific Islander Only\"),\n",
        "(6,\"White-Black\"),\n",
        "(7,\"White-AI\"),\n",
        "(8,\"White-Asian\"),\n",
        "(9,\"White-HP\"),\n",
        "(10,\"Black-AI\"),\n",
        "(11,\"Black-Asian\"),\n",
        "(12,\"Black-HP\"),\n",
        "(13,\"AI-Asian\"),\n",
        "(14,\"AI-HP\"),\n",
        "(15,\"Asian-HP\"),\n",
        "(16,\"W-B-AI\"),\n",
        "(17,\"W-B-A\"),\n",
        "(18,\"W-B-HP\"),\n",
        "(19,\"W-AI-A\"),\n",
        "(20,\"W-AI-HP\"),\n",
        "(21,\"W-A-HP\"),\n",
        "(22,\"B-AI-A\"),\n",
        "(23,\"W-B-AI-A\"),\n",
        "(24,\"W-AI-A-HP\"),\n",
        "(25,\"Other 3 Race Combinations\"),\n",
        "(26 ,\"Other 4 and 5 Race Combinations\")]\n",
        "columns = [\"code\", \"races\"]\n",
        "race_df = spark.createDataFrame(race, columns)"
      ],
      "metadata": {
        "id": "XZCOtB9DzN_Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a local temporary view with these DataFrames\n",
        "census.createOrReplaceTempView(\"census_tab\")\n",
        "geo_division_df.createOrReplaceTempView(\"geo_division\")\n",
        "family_income_df.createOrReplaceTempView(\"family_income\")\n",
        "race_df.createOrReplaceTempView(\"race\")\n",
        "#lookup_df.createOrReplaceTempView(\"lookup\")"
      ],
      "metadata": {
        "id": "OMXVHiWSzSA2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\tWhat is the count of responders per family income range (show top 10)?\n",
        "question_1 = spark.sql(\"\"\"\n",
        "        SELECT income_range, count(*) cnt\n",
        "        FROM census_tab c\n",
        "        JOIN Family_income f\n",
        "        ON c.Family_income_range = f.code\n",
        "        group by income_range\n",
        "        order by cnt desc\n",
        "        limit 10;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCx2KYeCzWJL",
        "outputId": "c201c7d2-11da-41e4-ae82-8eb78cc1b2b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+\n",
            "|      income_range| cnt|\n",
            "+------------------+----+\n",
            "|100,000 TO 149,999|4964|\n",
            "|   150,000 OR MORE|4881|\n",
            "|  75,000 TO 99,999|4073|\n",
            "|  60,000 TO 74,999|3526|\n",
            "|  50,000 TO 59,999|2671|\n",
            "|  40,000 TO 49,999|2621|\n",
            "|  35,000 TO 39,999|1800|\n",
            "|  20,000 TO 24,999|1793|\n",
            "|  30,000 TO 34,999|1735|\n",
            "|  25,000 TO 29,999|1517|\n",
            "+------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the count of responders per geographical division/location and race (show top 10)?\n",
        "Q2 = spark.sql(\"\"\"\n",
        "        SELECT g.geo_div, r.races, count(*) count\n",
        "        FROM census_tab c\n",
        "        JOIN geo_division g ON c.Geo_division = g.code\n",
        "        JOIN race r ON c.Race = r.code\n",
        "        GROUP BY g.geo_div, r.races\n",
        "        ORDER BY count DESC\n",
        "        LIMIT 10;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jErEPj2ALG1",
        "outputId": "c744413b-5490-4ad7-d553-5466bb5cd99c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------+-----+\n",
            "|           geo_div|     races|count|\n",
            "+------------------+----------+-----+\n",
            "|           PACIFIC|White Only| 9112|\n",
            "|    SOUTH ATLANTIC|White Only| 8280|\n",
            "|          MOUNTAIN|White Only| 3217|\n",
            "|    SOUTH ATLANTIC|Black Only| 2860|\n",
            "|           PACIFIC|Asian Only| 1932|\n",
            "|WEST SOUTH CENTRAL|White Only| 1927|\n",
            "|EAST SOUTH CENTRAL|White Only| 1834|\n",
            "|       NEW ENGLAND|White Only| 1043|\n",
            "|           PACIFIC|Black Only|  633|\n",
            "|EAST SOUTH CENTRAL|Black Only|  583|\n",
            "+------------------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many responders do not have telephone in their house, but can access a telephone elsewhere and telephone interview is accepted?\n",
        "q3 = spark.sql(\"\"\"\n",
        "        SELECT COUNT(*) \n",
        "        FROM census_tab c\n",
        "        WHERE Telephone_in_house = \"NO\"\n",
        "        AND Access_to_Tel = \"YES\"\n",
        "        AND Phone_interview_acc = \"YES\";\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jRpcMmWYJQv",
        "outputId": "02cdfbf8-bf4f-4b5c-bdf3-b9ff50dcc861"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|     154|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many responders can access to a telephone, but telephone interview is not accepted?\n",
        "q4 = spark.sql(\"\"\"\n",
        "        SELECT COUNT(*) \n",
        "        FROM census_tab c\n",
        "        WHERE Access_to_Tel = \"YES\"\n",
        "        AND Phone_interview_acc = \"NO\";\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OYwfDqEdlVb",
        "outputId": "8a53194b-e3be-44e1-bff6-2c92e87b0a69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|       0|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrxImiOfoANZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}